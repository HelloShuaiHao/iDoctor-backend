from fastapi import FastAPI, UploadFile, File, Form, BackgroundTasks, Request, HTTPException
from fastapi.middleware.cors import CORSMiddleware

import shutil, os, time, threading, hashlib, json
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    force=True
)
logger = logging.getLogger(__name__)

# Force immediate flush
import sys
for handler in logging.root.handlers:
    handler.flush = lambda: sys.stdout.flush() or sys.stderr.flush()

# ==================== å•†ä¸šåŒ–ç³»ç»Ÿé›†æˆ ====================
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®å¼€å…³
ENABLE_AUTH = os.getenv("ENABLE_AUTH", "false").lower() == "true"
ENABLE_QUOTA = os.getenv("ENABLE_QUOTA", "false").lower() == "true"

# å¯¼å…¥ä¸­é—´ä»¶ï¼ˆä»…åœ¨éœ€è¦æ—¶ï¼‰
COMMERCIAL_AVAILABLE = False
auth_middleware = None
quota_middleware = None
init_quota_manager = None

if ENABLE_AUTH or ENABLE_QUOTA:
    try:
        import sys
        commercial_path = os.path.abspath('commercial')
        if commercial_path not in sys.path:
            sys.path.insert(0, commercial_path)
        
        if ENABLE_AUTH:
            from integrations.middleware.auth_middleware import auth_middleware
        
        if ENABLE_QUOTA:
            from integrations.middleware.quota_middleware import (
                quota_middleware,
                init_quota_manager
            )
        
        COMMERCIAL_AVAILABLE = True
        logger.info(f"ğŸ” è®¤è¯ä¸­é—´ä»¶: {'âœ… å¯ç”¨' if ENABLE_AUTH else 'âŒ å…³é—­'}")
        logger.info(f"ğŸ“Š é…é¢ä¸­é—´ä»¶: {'âœ… å¯ç”¨' if ENABLE_QUOTA else 'âŒ å…³é—­'}")
    except ImportError as e:
        logger.error(f"âš ï¸ å•†ä¸šåŒ–ä¸­é—´ä»¶å¯¼å…¥å¤±è´¥: {e}")
        logger.warning("âš ï¸ å•†ä¸šåŒ–åŠŸèƒ½å·²ç¦ç”¨")
        COMMERCIAL_AVAILABLE = False
        ENABLE_AUTH = False
        ENABLE_QUOTA = False
else:
    logger.info("â„¹ï¸  å•†ä¸šåŒ–åŠŸèƒ½æœªå¯ç”¨ï¼ˆå¼€å‘æ¨¡å¼ï¼‰")
# ==================== å•†ä¸šåŒ–ç³»ç»Ÿé›†æˆç»“æŸ ====================
try:
    import psutil  # optional for memory diagnostics
except ImportError:  # graceful fallback
    psutil = None
import zipfile
import zipfile
import os
import traceback
from all_new import main 
from all_new import l3_detect, continue_after_l3, generate_sagittal, SAGITTAL_CLEAN
from fastapi.responses import FileResponse
from fastapi import FastAPI, UploadFile, File, Form, Query

from compute import compute_manual_middle_statistics


logger.info("Creating FastAPI app...")
app = FastAPI()
logger.info("FastAPI app created")

# å…¨å±€ä»»åŠ¡çŠ¶æ€å­—å…¸ (åå°è®¡ç®—)
task_status = {}

# ä¸Šä¼ è¿›åº¦çŠ¶æ€: {upload_id: {status, received, total, percent, message, folder, filename, started_at}}
upload_status = {}

# æ¯ä¸ªç—…ä¾‹(patient_date)çš„äº’æ–¥é”ï¼Œé˜²æ­¢å¹¶å‘ä¸Šä¼ /å¤„ç†è¦†ç›–
_patient_locks = {}
def _get_patient_lock(key: str):
    return _patient_locks.setdefault(key, threading.Lock())

# æ¯ä¸ªä»»åŠ¡çš„é”ï¼Œé˜²æ­¢é‡å¤æäº¤
task_locks = {}
def _get_task_lock(task_id: str):
    return task_locks.setdefault(task_id, threading.Lock())

CHUNK_SIZE = 1024 * 512  # 512KB chunk

# Debug flag (enable extra instrumentation)
DEBUG_ENABLED = os.environ.get("IDOCTOR_DEBUG", "1") not in ("0", "false", "False")

def _patient_root(patient_name: str, study_date: str, user_id: str = None):
    """è·å–æ‚£è€…æ•°æ®æ ¹ç›®å½•ï¼ˆæ”¯æŒç”¨æˆ·éš”ç¦»ï¼‰
    
    Args:
        patient_name: æ‚£è€…åç§°
        study_date: ç ”ç©¶æ—¥æœŸ
        user_id: ç”¨æˆ·IDï¼ˆå¯é€‰ï¼‰
    
    Returns:
        æ•°æ®ç›®å½•è·¯å¾„
    """
    folder_name = f"{patient_name}_{study_date}"
    
    if user_id and ENABLE_AUTH:
        # è®¤è¯æ¨¡å¼ï¼šæ•°æ®æŒ‰ç”¨æˆ·éš”ç¦»
        user_data_root = os.path.join(DATA_ROOT, str(user_id))
        os.makedirs(user_data_root, exist_ok=True)
        return os.path.join(user_data_root, folder_name)
    else:
        # å¼€å‘æ¨¡å¼ï¼šå…±äº«æ•°æ®
        return os.path.join(DATA_ROOT, folder_name)

def _output_dir(patient_name: str, study_date: str, user_id: str = None):
    return os.path.join(_patient_root(patient_name, study_date, user_id), "output")

def _pipeline_log_path(output_folder: str):
    return os.path.join(output_folder, "pipeline_debug.log")

def _safe_mkdir(path: str):
    os.makedirs(path, exist_ok=True)

def _append_log_line(output_folder: str, line: str):
    ts = time.strftime("%Y-%m-%d %H:%M:%S")
    full = f"[{ts}] {line}"
    print(full, flush=True)
    if not output_folder:
        return
    try:
        with open(_pipeline_log_path(output_folder), "a", encoding="utf-8") as f:
            f.write(full + "\n")
    except Exception:
        pass

def _hash_input_dir(input_dir: str):
    files = [f for f in os.listdir(input_dir) if f.lower().endswith((".dcm", ".dcm.pk"))]
    files.sort()
    h = hashlib.sha256()
    sizes = []
    for f in files:
        p = os.path.join(input_dir, f)
        try:
            st = os.stat(p)
            h.update(f.encode())
            h.update(str(st.st_size).encode())
            sizes.append(st.st_size)
        except Exception:
            continue
    return {
        "count": len(files),
        "hash": h.hexdigest(),
        "total_bytes": sum(sizes)
    }

def _resource_snapshot():
    snap = {}
    if psutil:
        p = psutil.Process()
        with p.oneshot():
            mem = p.memory_info()
            snap["rss_mb"] = round(mem.rss / 1024 / 1024, 2)
            snap["cpu_percent"] = p.cpu_percent(interval=None)
            snap["num_threads"] = p.num_threads()
            snap["open_files"] = len(p.open_files())
    return snap
# å…è®¸çš„å‰ç«¯æ¥æº
origins = [
    "http://localhost:7500",
    "http://127.0.0.1:7500",
    "http://localhost:8080",  # Vue CLI é»˜è®¤ç«¯å£
    "http://127.0.0.1:8080",
    "http://localhost:3000",  # å¸¸ç”¨å¼€å‘ç«¯å£
    "http://127.0.0.1:3000",
    "http://ai.bygpu.com:55304",  # ä¸»å‰ç«¯ï¼ˆç«¯å£7500ï¼‰
    "https://ai.bygpu.com:55304",
    "http://ai.bygpu.com:55305",  # commercialå‰ç«¯ï¼ˆç«¯å£3000ï¼‰
    "https://ai.bygpu.com:55305",
    "http://ai.bygpu.com",
    "https://ai.bygpu.com",
    "http://ai.bygpu.com:55303",
    "https://ai.bygpu.com:55303",
]
logger.info("Adding CORS middleware...")
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
logger.info("CORS middleware added")

# ==================== SAM2 åˆ†å‰²æœåŠ¡é›†æˆ ====================
from sam2_client import get_sam2_client, init_sam2_client

SAM2_ENABLED = os.getenv("SAM2_ENABLED", "true").lower() == "true"
sam2_available = False

@app.on_event("startup")
async def startup_sam2():
    """Initialize SAM2 client on startup"""
    global sam2_available
    if SAM2_ENABLED:
        logger.info("ğŸ¤– Initializing SAM2 service...")
        sam2_available = await init_sam2_client()
        if sam2_available:
            logger.info("âœ… SAM2 service initialized successfully")
        else:
            logger.warning("âš ï¸  SAM2 service unavailable - one-click segmentation disabled")
    else:
        logger.info("â„¹ï¸  SAM2 service disabled")

# ==================== SAM2 åˆ†å‰²æœåŠ¡é›†æˆç»“æŸ ====================

# ==================== æ³¨å†Œå•†ä¸šåŒ–ä¸­é—´ä»¶ ====================
logger.info(f"Registering commercial middleware... COMMERCIAL_AVAILABLE={COMMERCIAL_AVAILABLE}, ENABLE_AUTH={ENABLE_AUTH}, ENABLE_QUOTA={ENABLE_QUOTA}")
if COMMERCIAL_AVAILABLE and (ENABLE_AUTH or ENABLE_QUOTA):
    if ENABLE_QUOTA and init_quota_manager:
        # åˆå§‹åŒ–é…é¢ç®¡ç†å™¨
        database_url = os.getenv("DATABASE_URL")
        if database_url:
            try:
                init_quota_manager(database_url)
                logger.info("âœ… é…é¢ç®¡ç†å™¨å·²åˆå§‹åŒ–")
            except Exception as e:
                logger.error(f"âš ï¸ é…é¢ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
                ENABLE_QUOTA = False
        else:
            logger.warning("âš ï¸ æœªé…ç½® DATABASE_URLï¼Œé…é¢åŠŸèƒ½å°†ä¸å¯ç”¨")
            ENABLE_QUOTA = False

    # æ³¨å†Œä¸­é—´ä»¶ (æ³¨æ„é¡ºåºï¼šFastAPI ä¸­é—´ä»¶æ˜¯åå‘æ‰§è¡Œï¼Œæ‰€ä»¥åæ³¨å†Œçš„å…ˆæ‰§è¡Œ)
    # æˆ‘ä»¬å¸Œæœ›ï¼šè¯·æ±‚ â†’ auth â†’ quota â†’ è·¯ç”±
    # æ‰€ä»¥æ³¨å†Œé¡ºåºï¼šå…ˆ quotaï¼Œå auth
    if ENABLE_QUOTA and quota_middleware:
        app.middleware("http")(quota_middleware)
        logger.info("âœ… é…é¢ä¸­é—´ä»¶å·²æ³¨å†Œ")
    
    if ENABLE_AUTH and auth_middleware:
        app.middleware("http")(auth_middleware)
        logger.info("âœ… è®¤è¯ä¸­é—´ä»¶å·²æ³¨å†Œ")
# ==================== å•†ä¸šåŒ–ä¸­é—´ä»¶æ³¨å†Œç»“æŸ ====================

# ==================== æ³¨å†Œç®¡ç†è·¯ç”± ====================
if COMMERCIAL_AVAILABLE and ENABLE_QUOTA:
    try:
        from integrations.admin_routes import router as admin_router
        app.include_router(admin_router)
        logger.info("âœ… ç®¡ç†APIè·¯ç”±å·²æ³¨å†Œ")
    except Exception as e:
        logger.error(f"âš ï¸ ç®¡ç†APIè·¯ç”±æ³¨å†Œå¤±è´¥: {e}")
# ==================== ç®¡ç†è·¯ç”±æ³¨å†Œç»“æŸ ====================

DATA_ROOT = "data"

############################## å¥åº·æ£€æŸ¥å’Œæµ‹è¯•æ¥å£ ##############################
@app.get("/status")
def get_status(request: Request):
    """æœåŠ¡çŠ¶æ€æ£€æŸ¥ï¼ˆç”¨äºæµ‹è¯•è®¤è¯ï¼‰"""
    user_id = getattr(request.state, "user_id", None)
    user_email = getattr(request.state, "user_email", None)
    return {
        "status": "ok",
        "authenticated": user_id is not None,
        "user_id": user_id,
        "user_email": user_email,
        "enable_auth": ENABLE_AUTH,
        "enable_quota": ENABLE_QUOTA
    }

############################## ä¸Šä¼ ç›¸å…³æ¥å£ ##############################
@app.get("/upload_status/{upload_id}")
def get_upload_status(upload_id: str):
    """æŸ¥è¯¢ä¸Šä¼ è¿›åº¦/çŠ¶æ€"""
    return upload_status.get(upload_id, {"status": "not_found"})

@app.post("/upload_dicom_zip")
async def upload_dicom_zip(
    request: Request,
    patient_name: str = Form(...),
    study_date: str = Form(...),
    file: UploadFile = File(...),
    file_size: int = Form(None)
):
    """æµå¼å®‰å…¨ä¸Šä¼  + è¿›åº¦ + å®¢æˆ·ç«¯æ–­å¼€æ¸…ç† + åŸå­æ›¿æ¢ input ç›®å½•ã€‚

    è¿”å›: {status, upload_id, folder, message}
    è¿›åº¦æŸ¥è¯¢: GET /upload_status/{upload_id}
    çŠ¶æ€è¯´æ˜:
      receiving -> unzip -> done / aborted / error
    """
    # è·å–ç”¨æˆ·ID
    user_id = getattr(request.state, "user_id", None)
    
    folder_name = f"{patient_name}_{study_date}"
    patient_root = _patient_root(patient_name, study_date, user_id)
    os.makedirs(patient_root, exist_ok=True)

    lock = _get_patient_lock(folder_name)
    if not lock.acquire(blocking=False):
        return {"status": "blocked", "message": "è¯¥ç—…ä¾‹æ­£åœ¨å ç”¨ä¸­, ç¨åå†è¯•"}

    upload_id = f"{folder_name}_{int(time.time())}"
    upload_status[upload_id] = {
        "status": "receiving",
        "received": 0,
        "total": file_size,
        "percent": 0.0,
        "message": "æ­£åœ¨æ¥æ”¶",
        "folder": folder_name,
        "filename": file.filename,
        "started_at": time.time()
    }

    tmp_zip_path = os.path.join(patient_root, file.filename + ".part")
    tmp_input_dir = os.path.join(patient_root, f"input_uploading_{int(time.time())}")
    final_input_dir = os.path.join(patient_root, "input")
    backup_old = None

    try:
        # 1. æµå¼å†™å…¥ zip .part
        with open(tmp_zip_path, "wb") as out_f:
            while True:
                if await request.is_disconnected():
                    raise RuntimeError("å®¢æˆ·ç«¯å·²æ–­å¼€")
                chunk = await file.read(CHUNK_SIZE)
                if not chunk:
                    break
                out_f.write(chunk)
                upload_status[upload_id]["received"] += len(chunk)
                if file_size:
                    upload_status[upload_id]["percent"] = round(upload_status[upload_id]["received"] / file_size * 100, 2)

        if file_size and upload_status[upload_id]["received"] != file_size:
            raise RuntimeError("æ¥æ”¶å­—èŠ‚ä¸ file_size ä¸ä¸€è‡´")

        upload_status[upload_id]["status"] = "unzip"
        upload_status[upload_id]["message"] = "è§£å‹ä¸­"

        # 2. è§£å‹åˆ°ä¸´æ—¶ç›®å½•
        os.makedirs(tmp_input_dir, exist_ok=True)
        try:
            with zipfile.ZipFile(tmp_zip_path, 'r') as zf:
                for name in zf.namelist():
                    base = os.path.basename(name)
                    if not base:
                        continue
                    with zf.open(name) as src, open(os.path.join(tmp_input_dir, base), "wb") as dst:
                        shutil.copyfileobj(src, dst)
        except Exception as e:
            raise RuntimeError(f"è§£å‹å¤±è´¥: {e}")

        # 3. åŸå­æ›¿æ¢ input ç›®å½•
        if os.path.isdir(final_input_dir):
            backup_old = final_input_dir + "_old"
            if os.path.isdir(backup_old):
                shutil.rmtree(backup_old, ignore_errors=True)
            os.replace(final_input_dir, backup_old)
        os.replace(tmp_input_dir, final_input_dir)
        if backup_old and os.path.isdir(backup_old):
            shutil.rmtree(backup_old, ignore_errors=True)

        # 4. å®Œæˆ
        upload_status[upload_id]["status"] = "done"
        upload_status[upload_id]["message"] = "ä¸Šä¼ å¹¶è§£å‹æˆåŠŸ"
        upload_status[upload_id]["percent"] = 100.0
        try:
            os.remove(tmp_zip_path)
        except Exception:
            pass

        # 5. åŒæ­¥å­˜å‚¨ä½¿ç”¨é‡åˆ°æ•°æ®åº“ï¼ˆå¦‚æœå¯ç”¨äº†é…é¢ï¼‰
        if ENABLE_QUOTA and user_id:
            try:
                from integrations.storage_tracker import sync_storage_quota_to_db
                from integrations.quota_manager import QuotaManager

                # å¼‚æ­¥åŒæ­¥å­˜å‚¨é…é¢
                import asyncio
                db_url = os.getenv("DATABASE_URL")
                if db_url:
                    qm = QuotaManager(db_url)
                    asyncio.create_task(sync_storage_quota_to_db(user_id, qm, DATA_ROOT))
                    logger.info(f"âœ… Triggered storage quota sync for user {user_id}")
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to sync storage quota: {e}")
                # å­˜å‚¨åŒæ­¥å¤±è´¥ä¸å½±å“ä¸Šä¼ 

        return {"status": "ok", "upload_id": upload_id, "folder": folder_name, "message": "ä¸Šä¼ è§£å‹å®Œæˆ"}
    except Exception as e:
        upload_status[upload_id]["status"] = "aborted"
        upload_status[upload_id]["message"] = f"å¤±è´¥: {e}"
        # æ¸…ç†ä¸´æ—¶
        try:
            if os.path.isfile(tmp_zip_path):
                os.remove(tmp_zip_path)
        except Exception:
            pass
        try:
            if os.path.isdir(tmp_input_dir):
                shutil.rmtree(tmp_input_dir, ignore_errors=True)
        except Exception:
            pass
        # å›æ»šæ—§ input
        if backup_old and not os.path.isdir(final_input_dir) and os.path.isdir(backup_old):
            os.replace(backup_old, final_input_dir)
        return {"status": "error", "upload_id": upload_id, "message": str(e)}
    finally:
        lock.release()

@app.post("/process/{patient_name}/{study_date}")
async def process_case(
    request: Request,
    patient_name: str, 
    study_date: str,
    background_tasks: BackgroundTasks
):
    # è·å–ç”¨æˆ·IDï¼ˆå¦‚æœå¯ç”¨äº†è®¤è¯ï¼‰
    user_id = getattr(request.state, "user_id", None)
    
    task_id = f"main_{patient_name}_{study_date}"
    
    # ä½¿ç”¨é”é˜²æ­¢å¹¶å‘æäº¤
    lock = _get_task_lock(task_id)
    if not lock.acquire(blocking=False):
        return {
            "status": "blocked",
            "task_id": task_id,
            "message": "ä»»åŠ¡æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·å‹¿é‡å¤æäº¤"
        }
    
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
        if task_id in task_status:
            status = task_status[task_id].get("status")
            # å¦‚æœæ˜¯æ­£åœ¨å¤„ç†ä¸­çš„ä»»åŠ¡ï¼Œè¿”å›ç°æœ‰çŠ¶æ€
            if status == "processing":
                started = task_status[task_id].get("started_at", 0)
                elapsed = time.time() - started
                # å¦‚æœä»»åŠ¡å·²ç»è¿è¡Œè¶…è¿‡10åˆ†é’Ÿï¼Œè®¤ä¸ºæ˜¯åƒµå°¸ä»»åŠ¡ï¼Œå…è®¸é‡æ–°æäº¤
                if elapsed < 600:  # 10åˆ†é’Ÿ
                    return {
                        "status": "processing",
                        "task_id": task_id,
                        "message": f"ä»»åŠ¡æ­£åœ¨å¤„ç†ä¸­(å·²è¿è¡Œ {int(elapsed)}ç§’)ï¼Œè¯·å‹¿é‡å¤æäº¤"
                    }
        
        # åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€
        task_status[task_id] = {
            "status": "processing",
            "progress": 0,
            "message": "ä»»åŠ¡å·²æäº¤",
            "started_at": time.time(),
            "submitted_at": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        
        folder_name = f"{patient_name}_{study_date}"
        patient_root = _patient_root(patient_name, study_date, user_id)
        input_folder = os.path.join(patient_root, "input")
        output_folder = os.path.join(patient_root, "output")
        os.makedirs(output_folder, exist_ok=True)

        print(f"[API] æäº¤å…¨æµç¨‹åå°ä»»åŠ¡: {task_id}")
        
        # æäº¤åå°ä»»åŠ¡
        background_tasks.add_task(_run_main_process, task_id, input_folder, output_folder)
        
        return {
            "status": "submitted",
            "task_id": task_id,
            "message": "å…¨æµç¨‹ä»»åŠ¡å·²æäº¤åˆ°åå°å¤„ç†ï¼Œè¯·è½®è¯¢ /task_status/{task_id} æŸ¥çœ‹è¿›åº¦"
        }
    finally:
        lock.release()

def _run_main_process(task_id: str, input_folder: str, output_folder: str):
    """åå°ä»»åŠ¡ï¼šæ‰§è¡Œ main å…¨æµç¨‹ (åŠ è°ƒè¯•æ—¥å¿—)"""
    start = time.time()
    snap_before = _resource_snapshot() if DEBUG_ENABLED else {}
    if DEBUG_ENABLED:
        _append_log_line(output_folder, f"[TASK {task_id}] ===== å¼€å§‹ main() input={input_folder}")
        inp_sig = _hash_input_dir(input_folder) if os.path.isdir(input_folder) else {"error": "input_missing"}
        _append_log_line(output_folder, f"[TASK {task_id}] è¾“å…¥ç­¾å {json.dumps(inp_sig, ensure_ascii=False)}")
        _append_log_line(output_folder, f"[TASK {task_id}] èµ„æºå¿«ç…§(before) {snap_before}")
        # åˆ—å‡º output ç›®å½•ç°æœ‰å­ç›®å½•(ç¬¬äºŒæ¬¡è¿è¡Œæ—¶æœ€å…³é”®)
        if os.path.isdir(output_folder):
            existing = os.listdir(output_folder)
            _append_log_line(output_folder, f"[TASK {task_id}] ç°æœ‰outputå­é¡¹ç›®: {existing}")
    try:
        task_status[task_id]["progress"] = 10
        task_status[task_id]["message"] = "æ­£åœ¨å¤„ç†..."

        # å½»åº•æ¸…ç† full_overlay ç›®å½•
        full_overlay_dir = os.path.join(output_folder, "full_overlay")
        if os.path.isdir(full_overlay_dir):
            for f in os.listdir(full_overlay_dir):
                file_path = os.path.join(full_overlay_dir, f)
                if os.path.isfile(file_path):
                    try:
                        os.remove(file_path)
                    except Exception:
                        pass

        main(input_folder, output_folder)
        elapsed = time.time() - start
        if DEBUG_ENABLED:
            snap_after = _resource_snapshot()
            _append_log_line(output_folder, f"[TASK {task_id}] main() å®Œæˆ è€—æ—¶={elapsed:.2f}s èµ„æºafter={snap_after}")
        task_status[task_id] = {
            "status": "completed",
            "progress": 100,
            "message": "å…¨æµç¨‹å¤„ç†å®Œæˆ",
            "output_dir": output_folder,
            "started_at": task_status[task_id].get("started_at"),
            "completed_at": time.time(),
            "duration": elapsed
        }
    except Exception as e:
        tb = traceback.format_exc()
        if DEBUG_ENABLED:
            _append_log_line(output_folder, f"[TASK {task_id}] å¼‚å¸¸: {e}\n{tb}")
        task_status[task_id] = {
            "status": "failed",
            "progress": 0,
            "message": f"å¤„ç†å¤±è´¥: {str(e)}",
            "error": str(e),
            "started_at": task_status[task_id].get("started_at"),
            "failed_at": time.time()
        }

# è¿”å›æ‰€æœ‰æ–‡ä»¶å¤¹çš„ ç—…äºº-æ—¥æœŸ åˆ—è¡¨
@app.get("/list_patients")
def list_patients(request: Request):
    """åˆ—å‡ºæ‚£è€…ï¼ˆæ”¯æŒç”¨æˆ·éš”ç¦»ï¼‰"""
    user_id = getattr(request.state, "user_id", None)
    logger.info(f"list_patients called: user_id={user_id}, ENABLE_AUTH={ENABLE_AUTH}")

    if user_id and ENABLE_AUTH:
        # è®¤è¯æ¨¡å¼ï¼šåªåˆ—å‡ºè¯¥ç”¨æˆ·çš„æ‚£è€…
        user_data_root = os.path.join(DATA_ROOT, str(user_id))
        if not os.path.exists(user_data_root):
            return {"count": 0, "patients": []}
        search_root = user_data_root
    else:
        # å¼€å‘æ¨¡å¼ï¼šåˆ—å‡ºæ‰€æœ‰æ‚£è€…
        search_root = DATA_ROOT
    
    patient_folders = [
        name for name in os.listdir(search_root)
        if os.path.isdir(os.path.join(search_root, name)) and not name.startswith('.')
    ]
    # è½¬æ¢ä¸º ç—…äºº-æ—¥æœŸ æ ¼å¼
    patient_date_list = [
        name.replace("_", "-") for name in patient_folders
    ]
    return {
        "count": len(patient_date_list),
        "patients": patient_date_list
    }

# æ ¹æ®ç—…äººåå­—å’Œæ—¥æœŸï¼Œè¿”å› full_overlay æ–‡ä»¶å¤¹ä¸‹çš„å…³é”®æ•°æ®ï¼ˆä¸¤ä¸ª csv æ–‡ä»¶å’Œæ‰€æœ‰ä»¥ middle ç»“å°¾çš„å›¾ç‰‡ï¼‰
@app.get("/get_key_results/{patient_name}/{study_date}")
def get_key_results(request: Request, patient_name: str, study_date: str):
    user_id = getattr(request.state, "user_id", None)
    
    patient_root = _patient_root(patient_name, study_date, user_id)
    full_overlay_folder = os.path.join(patient_root, "output", "full_overlay")
    if not os.path.exists(full_overlay_folder):
        return {"error": "ç»“æœæ–‡ä»¶å¤¹ä¸å­˜åœ¨"}

    files = os.listdir(full_overlay_folder)
    csv_files = [f for f in files if f.endswith(".csv")]
    middle_images = [f for f in files if f.endswith("middle.png")]

    # è¯»å– CSV æ–‡ä»¶å†…å®¹
    csv_contents = {}
    for f in csv_files:
        file_path = os.path.join(full_overlay_folder, f)
        with open(file_path, "r", encoding="utf-8") as file:
            csv_contents[f] = file.read()

    # åªè¿”å› middle å›¾ç‰‡çš„æ–‡ä»¶å
    return {
        "csv_files": csv_contents,      # {æ–‡ä»¶å: å†…å®¹}
        "middle_images": middle_images  # [æ–‡ä»¶å, ...]
    }

# ç›´æ¥ä¼ è¾“å›¾ç‰‡æ–‡ä»¶
@app.get("/get_image/{patient_name}/{study_date}/{filename}")
def get_image(request: Request, patient_name: str, study_date: str, filename: str):
    user_id = getattr(request.state, "user_id", None)

    patient_root = _patient_root(patient_name, study_date, user_id)
    img_path = os.path.join(patient_root, "output", "full_overlay", filename)
    if not os.path.exists(img_path):
        return {"error": "å›¾ç‰‡ä¸å­˜åœ¨"}

    # åˆ›å»º FileResponse å¹¶æ·»åŠ  CORS å¤´
    response = FileResponse(img_path, media_type="image/png")

    # æ·»åŠ  CORS å¤´ä»¥æ”¯æŒè·¨åŸŸè®¿é—®
    origin = request.headers.get("origin")
    if origin:
        response.headers["Access-Control-Allow-Origin"] = origin
        response.headers["Access-Control-Allow-Credentials"] = "true"

    return response    

@app.post("/l3_detect/{patient_name}/{study_date}")
def api_l3_detect(request: Request, patient_name: str, study_date: str):
    # è·å–ç”¨æˆ·IDï¼ˆå¦‚æœå¯ç”¨äº†è®¤è¯ï¼‰
    user_id = getattr(request.state, "user_id", None)
    
    patient_root = _patient_root(patient_name, study_date, user_id)
    input_folder = os.path.join(patient_root, "input")
    output_folder = os.path.join(patient_root, "output")
    os.makedirs(output_folder, exist_ok=True)
    result = l3_detect(input_folder, output_folder)
    return result

@app.post("/continue_after_l3/{patient_name}/{study_date}")
async def api_continue_after_l3(
    request: Request,
    patient_name: str, 
    study_date: str,
    background_tasks: BackgroundTasks
):
    # è·å–ç”¨æˆ·IDï¼ˆå¦‚æœå¯ç”¨äº†è®¤è¯ï¼‰
    user_id = getattr(request.state, "user_id", None)
    
    task_id = f"cont_{patient_name}_{study_date}"
    
    # ä½¿ç”¨é”é˜²æ­¢å¹¶å‘æäº¤
    lock = _get_task_lock(task_id)
    if not lock.acquire(blocking=False):
        return {
            "status": "blocked",
            "task_id": task_id,
            "message": "ä»»åŠ¡æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·å‹¿é‡å¤æäº¤"
        }
    
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
        if task_id in task_status:
            status = task_status[task_id].get("status")
            if status == "processing":
                started = task_status[task_id].get("started_at", 0)
                elapsed = time.time() - started
                if elapsed < 600:  # 10åˆ†é’Ÿ
                    return {
                        "status": "processing",
                        "task_id": task_id,
                        "message": f"ä»»åŠ¡æ­£åœ¨å¤„ç†ä¸­(å·²è¿è¡Œ {int(elapsed)}ç§’)ï¼Œè¯·å‹¿é‡å¤æäº¤"
                    }
        
        # åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€
        task_status[task_id] = {
            "status": "processing",
            "progress": 0,
            "message": "ä»»åŠ¡å·²æäº¤",
            "started_at": time.time(),
            "submitted_at": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        
        patient_root = _patient_root(patient_name, study_date, user_id)
        input_folder = os.path.join(patient_root, "input")
        output_folder = os.path.join(patient_root, "output")
        
        print(f"[API] æäº¤åå°ä»»åŠ¡: {task_id}")
        print(f"[API] Input folder: {input_folder}")
        print(f"[API] Output folder: {output_folder}")
        
        # æäº¤åå°ä»»åŠ¡
        background_tasks.add_task(_run_continue_after_l3, task_id, input_folder, output_folder)
        
        return {
            "status": "submitted",
            "task_id": task_id,
            "message": "ä»»åŠ¡å·²æäº¤åˆ°åå°å¤„ç†ï¼Œè¯·è½®è¯¢ /task_status/{task_id} æŸ¥çœ‹è¿›åº¦"
        }
    finally:
        lock.release()

def _run_continue_after_l3(task_id: str, input_folder: str, output_folder: str):
    """åå°ä»»åŠ¡ï¼šæ‰§è¡Œ continue_after_l3"""
    start = time.time()
    try:
        if DEBUG_ENABLED:
            _append_log_line(output_folder, f"[TASK {task_id}] ===== å¼€å§‹ continue_after_l3() input={input_folder}")
            if os.path.isdir(output_folder):
                _append_log_line(output_folder, f"[TASK {task_id}] outputåˆå§‹: {os.listdir(output_folder)}")
        print(f"[åå°ä»»åŠ¡ {task_id}] å¼€å§‹å¤„ç†...")
        task_status[task_id]["progress"] = 10
        task_status[task_id]["message"] = "æ­£åœ¨è¯»å– DICOM å’Œ L3 mask..."
        result = continue_after_l3(input_folder, output_folder)
        elapsed = time.time() - start
        print(f"[åå°ä»»åŠ¡ {task_id}] å¤„ç†å®Œæˆ")
        if DEBUG_ENABLED:
            _append_log_line(output_folder, f"[TASK {task_id}] continue_after_l3() å®Œæˆ è€—æ—¶={elapsed:.2f}s")
        task_status[task_id] = {
            "status": "completed",
            "progress": 100,
            "message": "å¤„ç†å®Œæˆ",
            "result": result,
            "started_at": task_status[task_id].get("started_at"),
            "completed_at": time.time(),
            "duration": elapsed
        }
    except Exception as e:
        tb = traceback.format_exc()
        print(f"[åå°ä»»åŠ¡ {task_id}] å¤„ç†å¤±è´¥: {e}")
        if DEBUG_ENABLED:
            _append_log_line(output_folder, f"[TASK {task_id}] continue_after_l3 å¼‚å¸¸: {e}\n{tb}")
        task_status[task_id] = {
            "status": "failed",
            "progress": 0,
            "message": f"å¤„ç†å¤±è´¥: {str(e)}",
            "error": str(e),
            "started_at": task_status[task_id].get("started_at"),
            "failed_at": time.time()
        }

@app.get("/task_status/{task_id}")
def get_task_status(task_id: str):
    """æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€"""
    if task_id not in task_status:
        return {
            "status": "not_found",
            "message": "ä»»åŠ¡ä¸å­˜åœ¨"
        }
    return task_status[task_id]

@app.get("/list_tasks")
def list_tasks():
    """åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡åŠå…¶çŠ¶æ€"""
    return {
        "tasks": task_status,
        "count": len(task_status)
    }

@app.get("/debug_log/{patient_name}/{study_date}")
def get_debug_log(request: Request, patient_name: str, study_date: str, lines: int = 300):
    """è·å–æŒ‡å®šç—…ä¾‹ pipeline_debug.log æœ€å N è¡Œ"""
    user_id = getattr(request.state, "user_id", None)
    output_folder = _output_dir(patient_name, study_date, user_id)
    log_path = _pipeline_log_path(output_folder)
    if not os.path.isfile(log_path):
        raise HTTPException(status_code=404, detail="log ä¸å­˜åœ¨")
    if lines <= 0:
        lines = 200
    # è¯»å–å°¾éƒ¨
    data = []
    with open(log_path, "r", encoding="utf-8") as f:
        # ç®€æ˜“å°¾è¯»
        from collections import deque
        dq = deque(f, maxlen=lines)
        data = list(dq)
    return {"patient": patient_name, "study_date": study_date, "lines": len(data), "content": data}

@app.get("/get_output_image/{patient_name}/{study_date}/{folder}/{filename}")
def get_output_image(request: Request, patient_name: str, study_date: str, folder: str, filename: str):
    # folder ä¾‹å¦‚ L3_overlayã€L3_clean_maskã€L3_png ç­‰
    user_id = getattr(request.state, "user_id", None)
    patient_root = _patient_root(patient_name, study_date, user_id)
    file_path = os.path.join(patient_root, "output", folder, filename)
    if not os.path.exists(file_path):
        return {"error": "å›¾ç‰‡ä¸å­˜åœ¨"}

    # åˆ›å»º FileResponse å¹¶æ·»åŠ  CORS å¤´
    response = FileResponse(file_path, media_type="image/png")

    # æ·»åŠ  CORS å¤´ä»¥æ”¯æŒè·¨åŸŸè®¿é—®
    origin = request.headers.get("origin")
    if origin:
        response.headers["Access-Control-Allow-Origin"] = origin
        response.headers["Access-Control-Allow-Credentials"] = "true"

    return response

@app.post("/generate_sagittal/{patient_name}/{study_date}")
def api_generate_sagittal(request: Request, patient_name: str, study_date: str, force: int = Query(0)):
    # è·å–ç”¨æˆ·IDï¼ˆå¦‚æœå¯ç”¨äº†è®¤è¯ï¼‰
    user_id = getattr(request.state, "user_id", None)
    
    patient_root = _patient_root(patient_name, study_date, user_id)
    input_folder = os.path.join(patient_root, "input")
    output_folder = os.path.join(patient_root, "output")
    if not os.path.isdir(input_folder):
        return {"error": "è¯·å…ˆä¸Šä¼  DICOM"}
    os.makedirs(output_folder, exist_ok=True)
    return generate_sagittal(input_folder, output_folder, force=bool(force))

@app.post("/upload_l3_mask/{patient}/{date}")
async def upload_l3_mask(request: Request, patient: str, date: str, file: UploadFile = File(...)):
    # è·å–ç”¨æˆ·IDï¼ˆå¦‚æœå¯ç”¨äº†è®¤è¯ï¼‰
    user_id = getattr(request.state, "user_id", None)
    
    patient_root = _patient_root(patient, date, user_id)
    output_folder = os.path.join(patient_root, "output")
    png_dir = os.path.join(output_folder, "L3_png")
    if not os.path.exists(os.path.join(png_dir, SAGITTAL_CLEAN)):
        return {"error": "è¯·å…ˆè°ƒç”¨ /generate_sagittal"}

    mask_dir = os.path.join(output_folder, "L3_mask")
    clean_dir = os.path.join(output_folder, "L3_clean_mask")
    overlay_dir = os.path.join(output_folder, "L3_overlay")
    for d in [mask_dir, clean_dir, overlay_dir]:
        os.makedirs(d, exist_ok=True)

    save_path = os.path.join(mask_dir, SAGITTAL_CLEAN)
    with open(save_path, "wb") as f:
        f.write(await file.read())

    from sagit_save import clean_mask_folder, overlay_and_save
    clean_mask_folder(mask_dir, clean_dir)
    overlay_and_save(png_dir, clean_dir, overlay_dir)
    return {"status": "ok", "message": "æ‰‹åŠ¨ L3 mask å·²è¦†ç›–", "overlay": f"L3_overlay/{SAGITTAL_CLEAN}"}

@app.post("/upload_middle_manual_mask/{patient}/{date}")
async def upload_middle_manual_mask(
    request: Request,
    patient: str, date: str,
    psoas_mask: UploadFile = File(None),
    combo_mask: UploadFile = File(None)
):
    # è·å–ç”¨æˆ·IDï¼ˆå¦‚æœå¯ç”¨äº†è®¤è¯ï¼‰
    user_id = getattr(request.state, "user_id", None)
    
    patient_root = _patient_root(patient, date, user_id)
    output_folder = os.path.join(patient_root, "output")
    full_overlay_dir = os.path.join(output_folder, "full_overlay")
    manual_mask_dir = os.path.join(output_folder, "manual_middle_mask")
    axisal_dir = os.path.join(output_folder, "Axisal")

    # ç¡®ä¿ manual_middle_mask ç›®å½•å­˜åœ¨
    os.makedirs(manual_mask_dir, exist_ok=True)

    # æ¸…ç©º old æ–‡ä»¶ï¼ˆåªåˆ  middle ç›¸å…³å›¾ç‰‡å’Œ maskï¼Œä¸åˆ  csvï¼‰
    safe_clear_folder(full_overlay_dir, ["_middle.png"])
    safe_clear_folder(manual_mask_dir, ["_psoas.png", "_combo.png"])

    # è¯»å– full_overlay/hu_statistics_middle_only.csvï¼Œå®šä½ filename
    csv_path = os.path.join(full_overlay_dir, "hu_statistics_middle_only.csv")
    import pandas as pd
    if not os.path.isfile(csv_path):
        return {"error": "ç¼ºå°‘ hu_statistics_middle_only.csv"}
    df = pd.read_csv(csv_path)
    if "filename" not in df.columns or df.empty:
        return {"error": "CSV æ–‡ä»¶æ— æœ‰æ•ˆ filename"}
    middle_name = df.iloc[0]["filename"]  # ä¾‹å¦‚ slice_105_middle.png

    base_name = middle_name.replace("_middle.png", ".png")
    axisal_path = os.path.join(axisal_dir, base_name)
    if not os.path.isfile(axisal_path):
        return {"error": f"æœªæ‰¾åˆ°åŸå›¾ {base_name}"}

    # ä¿å­˜ psoas mask
    psoas_mask_path = os.path.join(manual_mask_dir, f"{base_name}_psoas.png")
    if psoas_mask is not None:
        with open(psoas_mask_path, "wb") as f:
            f.write(await psoas_mask.read())
    else:
        psoas_mask_path = None

    # ä¿å­˜ combo mask
    combo_mask_path = os.path.join(manual_mask_dir, f"{base_name}_combo.png")
    if combo_mask is not None:
        with open(combo_mask_path, "wb") as f:
            f.write(await combo_mask.read())
    else:
        combo_mask_path = None

    # ç»Ÿè®¡å¹¶ç”Ÿæˆ overlay
    result = compute_manual_middle_statistics(axisal_path, psoas_mask_path, combo_mask_path, full_overlay_dir, base_name)
    
    # æ¸…ç† NaN/Inf å€¼
    import math
    def clean_floats(obj):
        if isinstance(obj, dict):
            return {k: clean_floats(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [clean_floats(v) for v in obj]
        elif isinstance(obj, float):
            if math.isnan(obj) or math.isinf(obj):
                return None
        return obj
    
    return clean_floats(result)

# ==================== SAM2 åˆ†å‰²ç«¯ç‚¹ ====================
@app.post("/api/segmentation/sam2")
async def sam2_segment(
    request: Request,
    file: UploadFile = File(...),
    image_type: str = Form("auto"),
    patient_id: str = Form(None),
    slice_index: str = Form(None),
    click_points: str = Form(None)
):
    """
    SAM2 åˆ†å‰²ç«¯ç‚¹ (æ”¯æŒäº¤äº’å¼ç‚¹å‡»)

    Args:
        file: å›¾åƒæ–‡ä»¶ (PNG, JPEG)
        image_type: å›¾åƒç±»å‹ ("L3" æˆ– "middle" æˆ– "auto")
        patient_id: æ‚£è€…ID (å¯é€‰)
        slice_index: åˆ‡ç‰‡ç´¢å¼• (å¯é€‰)
        click_points: ç‚¹å‡»åæ ‡ JSON å­—ç¬¦ä¸² (å¯é€‰)
                     æ ¼å¼: '[{"x": 100, "y": 200, "label": 1}]'
                     label: 1=å‰æ™¯ç‚¹, 0=èƒŒæ™¯ç‚¹

    Returns:
        JSON response with mask_data (base64), confidence_score, processing_time_ms, cached, bounding_box
    """
    if not SAM2_ENABLED:
        raise HTTPException(status_code=503, detail="SAM2 service is disabled")

    sam2_client = get_sam2_client()

    # Check availability (async - will auto-refresh health check if needed)
    if not await sam2_client.is_available():
        raise HTTPException(
            status_code=503,
            detail="SAM2 service is currently unavailable. Please try again later."
        )

    try:
        # è¯»å–å›¾åƒæ•°æ®
        image_data = await file.read()

        # éªŒè¯å›¾åƒæ ¼å¼
        if not file.content_type or not file.content_type.startswith("image/"):
            raise HTTPException(
                status_code=400,
                detail=f"Invalid image format. Expected image/*, got {file.content_type}"
            )

        # è§£æç‚¹å‡»åæ ‡
        parsed_click_points = None
        if click_points:
            try:
                parsed_click_points = json.loads(click_points)
                logger.info(f"Received {len(parsed_click_points)} click points for segmentation")
            except json.JSONDecodeError as e:
                logger.warning(f"Failed to parse click_points: {e}")

        # è°ƒç”¨ SAM2 åˆ†å‰²
        mask_bytes, metadata = await sam2_client.segment_image(
            image_data=image_data,
            image_type=image_type,
            use_cache=True,
            click_points=parsed_click_points
        )

        if mask_bytes is None:
            error_msg = metadata.get("error", "Unknown error")
            raise HTTPException(status_code=500, detail=error_msg)

        # ç¼–ç  mask ä¸º base64
        import base64
        mask_base64 = base64.b64encode(mask_bytes).decode('utf-8')

        # æ„å»ºå“åº”
        response = {
            "mask_data": mask_base64,
            "confidence_score": metadata.get("confidence_score", 0.0),
            "processing_time_ms": metadata.get("processing_time_ms", 0),
            "cached": metadata.get("cached", False),
            "bounding_box": metadata.get("bounding_box"),
            "image_type": image_type,
            "patient_id": patient_id,
            "slice_index": slice_index
        }

        logger.info(
            f"SAM2 segmentation successful: "
            f"type={image_type}, confidence={response['confidence_score']:.3f}, "
            f"cached={response['cached']}, time={response['processing_time_ms']}ms"
        )

        return response

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"SAM2 segmentation error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Segmentation failed: {str(e)}")

@app.get("/api/segmentation/sam2/health")
async def sam2_health():
    """
    SAM2 æœåŠ¡å¥åº·æ£€æŸ¥ç«¯ç‚¹

    Returns:
        JSON response with SAM2 service status
    """
    sam2_client = get_sam2_client()

    return {
        "enabled": SAM2_ENABLED,
        "available": await sam2_client.is_available(),
        "cache_stats": sam2_client.get_cache_stats()
    }

# ==================== SAM2 åˆ†å‰²ç«¯ç‚¹ç»“æŸ ====================

def safe_clear_folder(folder, patterns):
    if not os.path.isdir(folder):
        return
    for fname in os.listdir(folder):
        for pat in patterns:
            if fname.endswith(pat):
                try:
                    os.remove(os.path.join(folder, fname))
                except Exception:
                    pass